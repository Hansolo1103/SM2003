{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sohan M\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchinfo import summary\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./concrete_cracked_images/train/\"\n",
    "test_dir = \"./concrete_cracked_images/test/\"\n",
    "\n",
    "# Setup ImageNet normalization levels (turns all images into similar distribution as ImageNet)\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Create starter transform\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=90),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])           \n",
    "\n",
    "# Create datasets\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root = train_dir, transform = train_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 28718\n",
       "    Root location: ./concrete_cracked_images/train/\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               RandomRotation(degrees=[-90.0, 90.0], interpolation=nearest, expand=False, fill=0)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.ImageFolder(root = test_dir, transform = test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 11282\n",
       "    Root location: ./concrete_cracked_images/test/\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers= 4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False , num_workers=4)\n",
    "classes = (\"negative\", \"positive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import conv2d, max_pool2d\n",
    "from torch.nn import Dropout, Linear\n",
    "from torch.nn.modules import MaxPool2d, ReLU, linear, padding\n",
    "from torch.nn.modules.pooling import MaxPool3d\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample):\n",
    "        super().__init__()\n",
    "        if downsample:\n",
    "            self.conv1 = nn.Conv2d(\n",
    "                in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(\n",
    "                in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "            self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels,\n",
    "                               kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, input):\n",
    "        shortcut = self.shortcut(input)\n",
    "        input = nn.ReLU()(self.bn1(self.conv1(input)))\n",
    "        input = nn.ReLU()(self.bn2(self.conv2(input)))\n",
    "        input = input + shortcut\n",
    "        return nn.ReLU()(input)\n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBottleneckBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample):\n",
    "        super().__init__()\n",
    "        self.downsample = downsample\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels//4,\n",
    "                               kernel_size=1, stride=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels//4, out_channels//4, kernel_size=3, stride=2 if downsample else 1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(out_channels//4, out_channels, kernel_size=1, stride=1)\n",
    "\n",
    "        if self.downsample or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
    "                          stride=2 if self.downsample else 1),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels//4)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels//4)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, input):\n",
    "        shortcut = self.shortcut(input)\n",
    "        input = nn.ReLU()(self.bn1(self.conv1(input)))\n",
    "        input = nn.ReLU()(self.bn2(self.conv2(input)))\n",
    "        input = nn.ReLU()(self.bn3(self.conv3(input)))\n",
    "        input = input + shortcut\n",
    "        return nn.ReLU()(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels, resblock, repeat, useBottleneck=False, outputs=1000):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        if useBottleneck:\n",
    "            filters = [64, 256, 512, 1024, 2048]\n",
    "        else:\n",
    "            filters = [64, 64, 128, 256, 512]\n",
    "\n",
    "        self.layer1 = nn.Sequential()\n",
    "        self.layer1.add_module('conv2_1', resblock(filters[0], filters[1], downsample=False))\n",
    "        for i in range(1, repeat[0]):\n",
    "                self.layer1.add_module('conv2_%d'%(i+1,), resblock(filters[1], filters[1], downsample=False))\n",
    "\n",
    "        self.layer2 = nn.Sequential()\n",
    "        self.layer2.add_module('conv3_1', resblock(filters[1], filters[2], downsample=True))\n",
    "        for i in range(1, repeat[1]):\n",
    "                self.layer2.add_module('conv3_%d' % (\n",
    "                    i+1,), resblock(filters[2], filters[2], downsample=False))\n",
    "\n",
    "        self.layer3 = nn.Sequential()\n",
    "        self.layer3.add_module('conv4_1', resblock(filters[2], filters[3], downsample=True))\n",
    "        for i in range(1, repeat[2]):\n",
    "            self.layer3.add_module('conv2_%d' % (\n",
    "                i+1,), resblock(filters[3], filters[3], downsample=False))\n",
    "\n",
    "        self.layer4 = nn.Sequential()\n",
    "        self.layer4.add_module('conv5_1', resblock(filters[3], filters[4], downsample=True))\n",
    "        for i in range(1, repeat[3]):\n",
    "            self.layer4.add_module('conv3_%d'%(i+1,),resblock(filters[4], filters[4], downsample=False))\n",
    "\n",
    "        self.gap = torch.nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = torch.nn.Linear(filters[4], outputs)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.layer0(input)\n",
    "        input = self.layer1(input)\n",
    "        input = self.layer2(input)\n",
    "        input = self.layer3(input)\n",
    "        input = self.layer4(input)\n",
    "        input = self.gap(input)\n",
    "        \n",
    "        input = torch.flatten(input, start_dim=1)\n",
    "        input = self.fc(input)\n",
    "\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (layer0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (conv2_1): ResBottleneckBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2_2): ResBottleneckBlock(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2_3): ResBottleneckBlock(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (conv3_1): ResBottleneckBlock(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv3_2): ResBottleneckBlock(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv3_3): ResBottleneckBlock(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv3_4): ResBottleneckBlock(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (conv4_1): ResBottleneckBlock(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2_2): ResBottleneckBlock(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2_3): ResBottleneckBlock(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2_4): ResBottleneckBlock(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2_5): ResBottleneckBlock(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2_6): ResBottleneckBlock(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (conv5_1): ResBottleneckBlock(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv3_2): ResBottleneckBlock(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv3_3): ResBottleneckBlock(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50 = ResNet(3, ResBottleneckBlock, [\n",
    "                  3, 4, 6, 3], useBottleneck=True, outputs=1000)\n",
    "resnet50.to(torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.np()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "#Get some random training images\n",
    "dataiter = iter(train_dataloader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(99)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader,model):\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "\n",
    "            # forward + backward + optimize\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training of ResNet')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Sohan M\\Desktop\\110121103_SPML_Task1\\RESNET.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Sohan%20M/Desktop/110121103_SPML_Task1/RESNET.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(train_dataloader,model)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train(train_dataloader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        \n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / 708))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Sohan M\\Desktop\\110121103_SPML_Task1\\ALEXNET.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sohan%20M/Desktop/110121103_SPML_Task1/ALEXNET.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39msubplot(N_ROWS, ROW_IMG, index)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sohan%20M/Desktop/110121103_SPML_Task1/ALEXNET.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39maxis(\u001b[39m'\u001b[39m\u001b[39moff\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Sohan%20M/Desktop/110121103_SPML_Task1/ALEXNET.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(test_dataset\u001b[39m.\u001b[39;49mclasses[index], cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgray_r\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sohan%20M/Desktop/110121103_SPML_Task1/ALEXNET.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sohan%20M/Desktop/110121103_SPML_Task1/ALEXNET.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     model\u001b[39m.\u001b[39meval()\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACoAAAAzCAYAAADhGpoIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAU0lEQVR4nO3OwQnAMAwAsTT77+yu0MdBMUgT6JmZs8H9O/CVaE20JloTrYnWRGuiNdGaaE20JloTrYnWRGuiNdGaaE20JloTrYnWRGuiNdHamugLcwYDY6ESNkMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROW_IMG = 10\n",
    "N_ROWS = 5\n",
    "\n",
    "fig = plt.figure()\n",
    "for index in range(1, ROW_IMG * N_ROWS + 1):\n",
    "    plt.subplot(N_ROWS, ROW_IMG, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(test_dataset.data[index], cmap='gray_r')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        _, probs = model(test_dataset[index][0].unsqueeze(0))\n",
    "        \n",
    "    title = f'{torch.argmax(probs)} ({torch.max(probs * 100):.0f}%)'\n",
    "    \n",
    "    plt.title(title, fontsize=7)\n",
    "fig.suptitle('AlexNet - predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e8439e14a3c9d40e89aa31be7be8fe13eecb504fa234901bb42ac4ca6122099"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
